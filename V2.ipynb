{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9225180d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MexCulture142/\n",
    "# ├── images/\n",
    "# │   ├── Colonial_AcademiaDeBellasArtes_Queretaro_N_1.png\n",
    "# │   ├── Colonial_AcademiaDeBellasArtes_Queretaro_N_2.png\n",
    "# │   └── Colonial_AdvocacionesDeLaIglesiaDeSanSimon_Michoacan_N_1.png\n",
    "# │\n",
    "# ├── gazefixationsdensitymaps/\n",
    "# │   ├── Colonial_AcademiaDeBellasArtes_Queretaro_GFDM_N_1.png\n",
    "# │   ├── Colonial_AcademiaDeBellasArtes_Queretaro_GFDM_N_2.png\n",
    "# │   └── Colonial_AdvocacionesDeLaIglesiaDeSanSimon_Michoacan_GFDM_N_1.png\n",
    "# │\n",
    "# └── fixations/\n",
    "#     ├── Colonial_AcademiaDeBellasArtes_Queretaro_GazeFix_N_1.txt [cite: 1]\n",
    "#     ├── Colonial_AcademiaDeBellasArtes_Queretaro_GazeFix_N_2.txt [cite: 5]\n",
    "#     └── Colonial_AdvocacionesDeLaIglesiaDeSanSimon_Michoacan_GazeFix_N_1.txt [cite: 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94087fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "def redimensioneaza_si_comprima(cale_intrare, cale_iesire, dimensiune=(32, 32), calitate=95):\n",
    "    \"\"\"\n",
    "    Redimensionează o imagine la dimensiunea specificată și o salvează,\n",
    "    folosind filtrul LANCZOS pentru cea mai bună calitate la downsampling.\n",
    "\n",
    "    Parametri:\n",
    "    - cale_intrare (str): Calea către imaginea de intrare.\n",
    "    - cale_iesire (str): Calea unde se va salva imaginea redimensionată.\n",
    "    - dimensiune (tuple): Dimensiunea dorită (implicit 32x32).\n",
    "    - calitate (int): Calitatea de compresie JPEG (1-100). Ignorată pentru PNG.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 1. Deschide imaginea\n",
    "        img = Image.open(cale_intrare)\n",
    "        \n",
    "        # 2. Redimensionează imaginea\n",
    "        # Image.Resampling.LANCZOS este cel mai bun filtru pentru downsampling de înaltă calitate.\n",
    "        img_redimensionata = img.resize(dimensiune, Image.Resampling.LANCZOS)\n",
    "        \n",
    "        # 3. Salvează imaginea redimensionată\n",
    "        # Verifică extensia pentru a aplica calitatea de compresie (relevantă pentru JPEG)\n",
    "        extensie = os.path.splitext(cale_iesire)[1].lower()\n",
    "        \n",
    "        if extensie in ('.jpg', '.jpeg'):\n",
    "            # Salvare JPEG cu opțiuni de calitate și optimizare\n",
    "            img_redimensionata.save(cale_iesire, \"JPEG\", optimize=True, quality=calitate)\n",
    "        elif extensie == '.png':\n",
    "            # Salvare PNG (fără pierderi, dar putem optimiza compresia)\n",
    "            # Parametrul 'compress_level' poate fi 0 (fără compresie) la 9 (compresie maximă, mai lentă)\n",
    "            img_redimensionata.save(cale_iesire, \"PNG\", compress_level=9)\n",
    "        else:\n",
    "            # Salvare pentru alte formate, fără parametri specifici de compresie\n",
    "            img_redimensionata.save(cale_iesire)\n",
    "            \n",
    "        print(f\"Imaginea a fost redimensionată și salvată la: {cale_iesire}\")\n",
    "        print(f\"Dimensiune finală: {img_redimensionata.size}\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Eroare: Fișierul de intrare nu a fost găsit la {cale_intrare}\")\n",
    "    except Exception as e:\n",
    "        print(f\"A apărut o eroare: {e}\")\n",
    "\n",
    "# --- Exemplu de utilizare ---\n",
    "# if __name__ == \"__main__\":\n",
    "#     # Schimbă aceste căi cu fișierele tale reale\n",
    "#     fisier_intrare = \"MexCulture142\\gazefixationsdensitymaps\\Colonial_AcademiaDeBellasArtes_Queretaro_GFDM_N_1.png\" # sau .jpg\n",
    "#     fisier_iesire = \"harta_salienta_32x32.png\"    # Alege formatul de ieșire\n",
    "    \n",
    "#     # Creează un fișier fals pentru testare dacă nu există\n",
    "#     if not os.path.exists(fisier_intrare):\n",
    "#         try:\n",
    "#             # Creează o imagine simplă (ex. 128x128) pentru a testa scriptul\n",
    "#             img_test = Image.new('RGB', (128, 128), color = 'red')\n",
    "#             img_test.save(fisier_intrare)\n",
    "#             print(f\"Fișier de test '{fisier_intrare}' creat pentru demonstrație.\")\n",
    "#         except:\n",
    "#             print(f\"Atenție: Nu s-a putut crea un fișier de test. Asigură-te că imaginea '{fisier_intrare}' există.\")\n",
    "    \n",
    "#     redimensioneaza_si_comprima(fisier_intrare, fisier_iesire, calitate=90) # Ajustează calitatea (1-100) dacă salvezi în JPEG\n",
    "\n",
    "#     plt.figure(),plt.imshow(io.imread(fisier_intrare),cmap='gray')\n",
    "#     plt.figure(),plt.imshow(io.imread(fisier_iesire),cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ccb670",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.models import resnet34, ResNet34_Weights\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# --- 1. Definirea Arhitecturii Modelului (ResNet34 + Saliency Head) ---\n",
    "# (Această clasă rămâne neschimbată)\n",
    "\n",
    "class SaliencyModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Arhitectura modelului: ResNet34 (Backbone) + Saliency Head (Decodor).\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(SaliencyModel, self).__init__()\n",
    "        \n",
    "        # Încarcă ResNet34 pre-antrenat\n",
    "        base_model = resnet34(weights=ResNet34_Weights.IMAGENET1K_V1)\n",
    "        \n",
    "        # Extractorul de caracteristici (fără ultimele 2 straturi)\n",
    "        self.feature_extractor = nn.Sequential(*list(base_model.children())[:-2])\n",
    "        \n",
    "        # Capul de Saliență (Saliency Head)\n",
    "        # Transformă (512, 7, 7) -> (1, 32, 32)\n",
    "        self.saliency_head = nn.Sequential(\n",
    "            nn.Conv2d(512, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Upsample(size=(32, 32), mode='bilinear', align_corners=False),\n",
    "            nn.Conv2d(64, 1, kernel_size=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        features = self.feature_extractor(x)\n",
    "        saliency_map = self.saliency_head(features)\n",
    "        return saliency_map\n",
    "\n",
    "# --- 2. Definirea Setului de Date (Versiunea SIMPLĂ, FĂRĂ AUGMENTARE) ---\n",
    "\n",
    "class MexCultureDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Clasa Dataset personalizată, simplă.\n",
    "    Încarcă o imagine (Input) și harta sa GFDM (Target)\n",
    "    și aplică transformările de bază (Resize, ToTensor).\n",
    "    \"\"\"\n",
    "    def __init__(self, root_dir, transform_input=None, target_size=(32, 32)):\n",
    "        self.image_dir = os.path.join(root_dir, 'images')\n",
    "        self.gfdm_dir = os.path.join(root_dir, 'gazefixationsdensitymaps')\n",
    "        \n",
    "        self.image_files = [f for f in os.listdir(self.image_dir) if f.endswith('.png')]\n",
    "        \n",
    "        # Primește transformările pentru Input (X) ca parametru\n",
    "        self.transform_input = transform_input\n",
    "        self.target_size = target_size\n",
    "        \n",
    "        # Transformare standard pentru harta țintă (GFDM - Y)\n",
    "        self.transform_target = transforms.Compose([\n",
    "            transforms.Resize(self.target_size, \n",
    "                              interpolation=transforms.InterpolationMode.BILINEAR),\n",
    "            transforms.ToTensor() \n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        # Returnează numărul total de eșantioane (imagini)\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # --- A. Încărcare Fișiere ---\n",
    "        img_name = self.image_files[idx]\n",
    "        img_path = os.path.join(self.image_dir, img_name)\n",
    "        \n",
    "        gfdm_name = img_name.replace('.png', '').replace('_N_', '_GFDM_N_') + '.png'\n",
    "        gfdm_path = os.path.join(self.gfdm_dir, gfdm_name)\n",
    "        \n",
    "        # Deschide imaginea (X) și harta (Y)\n",
    "        input_image = Image.open(img_path).convert('RGB')\n",
    "        target_gfdm_image = Image.open(gfdm_path).convert('L')\n",
    "        \n",
    "        # --- B. Aplicare Transformări (Fără Augmentare) ---\n",
    "        \n",
    "        # Aplică transformările de intrare (Resize, ToTensor, Normalize)\n",
    "        if self.transform_input:\n",
    "            input_tensor = self.transform_input(input_image)\n",
    "        \n",
    "        # Aplică transformările țintă (Resize 32x32, ToTensor)\n",
    "        target_tensor = self.transform_target(target_gfdm_image)\n",
    "        \n",
    "        return input_tensor, target_tensor\n",
    "\n",
    "# --- 3. Execuția Principală (Antrenarea) ---\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # Parametrii\n",
    "    ROOT_DATA_DIR = 'MexCulture142' # Asumând că folderele sunt în directorul curent\n",
    "    BATCH_SIZE = 2      \n",
    "    NUM_EPOCHS = 10     \n",
    "    LEARNING_RATE = 0.0001\n",
    "    \n",
    "    # Detectează GPU\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Se utilizează dispozitivul: {device}\")\n",
    "\n",
    "    # --- Definirea Transformărilor de Bază (Fără Augmentare) ---\n",
    "    # Acestea sunt necesare pentru a pregăti imaginea pentru ResNet\n",
    "    input_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)), # Redimensionează imaginea la 224x224\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    # Inițializare Dataset\n",
    "    print(f\"Încărcare set de date din: {ROOT_DATA_DIR}\")\n",
    "    try:\n",
    "        # Creează setul de date și pasează transformările de intrare\n",
    "        train_dataset = MexCultureDataset(root_dir=ROOT_DATA_DIR, \n",
    "                                          transform_input=input_transform)\n",
    "        \n",
    "        # Inițializare DataLoader\n",
    "        train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "        \n",
    "        print(f\"Set de date încărcat. Am găsit {len(train_dataset)} eșantioane.\")\n",
    "\n",
    "        # Inițializare Model, Loss și Optimizer\n",
    "        model = SaliencyModel()\n",
    "        model.to(device) # Mută modelul pe GPU\n",
    "        \n",
    "        criterion = nn.MSELoss() \n",
    "        optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "        print(\"--- Începere Antrenare (Fără Augmentare) ---\")\n",
    "\n",
    "        # Bucla de Antrenare\n",
    "        for epoch in range(NUM_EPOCHS):\n",
    "            model.train() \n",
    "            epoch_loss = 0.0\n",
    "            \n",
    "            for inputs, targets in train_loader:\n",
    "                # Mută datele pe GPU\n",
    "                inputs = inputs.to(device)\n",
    "                targets = targets.to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # Forward pass\n",
    "                predictions = model(inputs)\n",
    "                \n",
    "                # Calcul Loss\n",
    "                loss = criterion(predictions, targets)\n",
    "                \n",
    "                # Backward pass și optimizare\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                epoch_loss += loss.item()\n",
    "            \n",
    "            print(f\"Epoch {epoch+1}/{NUM_EPOCHS}, Loss: {epoch_loss / len(train_loader):.6f}, Accuracy: {100 - (epoch_loss / len(train_loader))*100:.2f}%\")\n",
    "\n",
    "        print(\"--- Antrenare Finalizată ---\")\n",
    "        \n",
    "        # Salvarea modelului antrenat\n",
    "        torch.save(model.state_dict(), 'saliency_resnet34.pth')\n",
    "        print(\"Modelul antrenat a fost salvat ca 'saliency_resnet34.pth'\")\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"\\nEROARE: Nu am putut găsi folderele de date.\")\n",
    "        print(f\"Asigură-te că scriptul rulează în folderul care conține 'images/' și 'gazefixationsdensitymaps/'.\")\n",
    "        print(f\"Detalii: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c25a826",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.models import resnet34, ResNet34_Weights\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class SaliencyModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Arhitectura modelului: ResNet34 (Backbone) + Saliency Head (Decodor).\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(SaliencyModel, self).__init__()\n",
    "        \n",
    "        # Încarcă ResNet34 pre-antrenat\n",
    "        base_model = resnet34(weights=ResNet34_Weights.IMAGENET1K_V1)\n",
    "        \n",
    "        # Extractorul de caracteristici (fără ultimele 2 straturi)\n",
    "        self.feature_extractor = nn.Sequential(*list(base_model.children())[:-2])\n",
    "        \n",
    "        # Capul de Saliență (Saliency Head)\n",
    "        # Transformă (512, 7, 7) -> (1, 32, 32)\n",
    "        self.saliency_head = nn.Sequential(\n",
    "            nn.Conv2d(512, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Upsample(size=(32, 32), mode='bilinear', align_corners=False),\n",
    "            nn.Conv2d(64, 1, kernel_size=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        features = self.feature_extractor(x)\n",
    "        saliency_map = self.saliency_head(features)\n",
    "        return saliency_map\n",
    "\n",
    "# Testare model\n",
    "MODEL_PATH = 'saliency_resnet34_weights.pth'\n",
    "OUTPUT_NAME = 'predicted_saliency_map.png'\n",
    "\n",
    "# Suprimă avertismentele (unele pot apărea la descărcare)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- 3. Pregătirea Modelului ---\n",
    "print(\"Se pregătește modelul...\")\n",
    "# Detectează GPU dacă e disponibil\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Inițiază modelul și încarcă greutățile salvate\n",
    "model = SaliencyModel()\n",
    "try:\n",
    "    model.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n",
    "except FileNotFoundError:\n",
    "    print(f\"EROARE: Nu am găsit fișierul modelului '{MODEL_PATH}'.\")\n",
    "    print(\"Asigură-te că ai rulat scriptul de antrenare și ai salvat modelul.\")\n",
    "    exit()\n",
    "\n",
    "# Mută modelul pe GPU/CPU\n",
    "model.to(device)\n",
    "# !!! FOARTE IMPORTANT: Setează modelul în modul de evaluare !!!\n",
    "# Acest lucru dezactivează straturi ca Dropout sau Batch Normalization\n",
    "model.eval() \n",
    "\n",
    "print(f\"Modelul a fost încărcat de la '{MODEL_PATH}' și rulează pe {device}.\")\n",
    "\n",
    "# --- 4. Pregătirea Imaginii ---\n",
    "# Definirea transformărilor (TREBUIE să fie identice cu cele de la antrenare)\n",
    "input_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "image = Image.open('MexCulture142/images/Colonial_ElTemploDeSanFrancisco_Queretaro_N_1.png').convert('RGB')\n",
    "\n",
    "# Aplică transformările\n",
    "input_tensor = input_transform(image)\n",
    "\n",
    "# Adaugă o dimensiune \"batch\" (modelul așteaptă [Batch, Canale, H, W])\n",
    "input_tensor = input_tensor.unsqueeze(0) \n",
    "\n",
    "# Mută tensorul pe același dispozitiv ca modelul\n",
    "input_tensor = input_tensor.to(device)\n",
    "\n",
    "# --- 5. Rularea Predicției (Inferență) ---\n",
    "print(\"Se rulează predicția...\")\n",
    "# Oprește calculul gradienților pentru a economisi memorie și viteză\n",
    "with torch.no_grad():\n",
    "    # Rulează modelul\n",
    "    prediction_tensor = model(input_tensor) # Ieșire: (1, 1, 32, 32)\n",
    "\n",
    "# --- 6. Salvarea Rezultatului ---\n",
    "# Mută tensorul înapoi pe CPU (dacă e pe GPU) și convertește-l în NumPy\n",
    "# .squeeze() elimină dimensiunile de 1 (Batch și Canal)\n",
    "prediction_np = prediction_tensor.squeeze().cpu().numpy()\n",
    "\n",
    "# Convertește din [0, 1] (float) în [0, 255] (uint8)\n",
    "output_array = (prediction_np * 255).astype(np.uint8)\n",
    "\n",
    "# Creează o imagine PIL din array\n",
    "output_image = Image.fromarray(output_array, 'L') # 'L' = Grayscale\n",
    "\n",
    "# Salvează imaginea\n",
    "output_image.save(OUTPUT_NAME)\n",
    "\n",
    "print(f\"\\n--- SUCCES ---\")\n",
    "print(f\"Harta de saliență a fost salvată ca '{OUTPUT_NAME}'.\")\n",
    "print(\"Aceasta este o imagine de 32x32. Pentru a o vedea mai bine, măriți-o.\")\n",
    "\n",
    "plt.figure(),plt.imshow(image,cmap='gray')\n",
    "plt.figure(),plt.imshow(output_image,cmap='gray')\n",
    "print(np.max(output_image))\n",
    "print(output_image)\n",
    "\n",
    "# upscale salieny map to original image size and show\n",
    "output_image_upscaled = output_image.resize(image.size, Image.Resampling.BILINEAR)\n",
    "output_image_upscaled.save('predicted_saliency_map_upscaled.png')\n",
    "print(f\"Harta de saliență redimensionată a fost salvată ca 'predicted_saliency_map_upscaled.png'.\")\n",
    "plt.figure(),plt.imshow(output_image_upscaled,cmap='gray')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
